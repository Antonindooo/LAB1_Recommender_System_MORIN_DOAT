{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Implementing Matrix Factorization from Scratch\n",
    "\n",
    "**Course:** Recommender Systems <br>\n",
    "**Professor:** Guilherme MEDEIROS MACHADO <br>\n",
    "**Topic:** Collaborative Filtering with Matrix Factorization\n",
    "\n",
    "---\n",
    "\n",
    "## Goal of the Exercise\n",
    "\n",
    "The objective of this exercise is to build a movie recommender system by implementing the **Matrix Factorization** algorithm from scratch using Python. We will use the famous **MovieLens 100k** dataset. By the end of this notebook, you will have:\n",
    "\n",
    "1.  Understood the theoretical foundations of matrix factorization.\n",
    "2.  Implemented the algorithm using **Stochastic Gradient Descent (SGD)**.\n",
    "3.  Trained your model on real-world movie rating data.\n",
    "4.  Evaluated your model's performance using Root Mean Squared Error (RMSE).\n",
    "5.  Generated personalized top-10 movie recommendations for a specific user.\n",
    "\n",
    "This exercise forbids the use of pre-built matrix factorization libraries (like `surprise`, `lightfm`, etc.) to ensure you gain a deep understanding of the inner workings of the algorithm.\n",
    "\n",
    "---\n",
    "\n",
    "## The Dataset: MovieLens 100k\n",
    "\n",
    "We will be using the MovieLens 100k dataset, a classic dataset in the recommender systems community. It contains:\n",
    "* 100,000 ratings (1-5) from...\n",
    "* 943 users on...\n",
    "* 1682 movies.\n",
    "\n",
    "You will need two files from this dataset:\n",
    "* `u.data`: The full dataset of 100k ratings. Each row is in the format: `user_id`, `item_id`, `rating`, `timestamp`.\n",
    "* `u.item`: Information about the movies (items). Each row contains the `item_id`, `movie_title`, and other metadata. We'll use it to get the movie names for our final recommendations.\n",
    "\n",
    "Let's start by downloading and exploring the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading MovieLens 100k dataset...\n",
      "Download and extraction complete.\n",
      "Data loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "      <td>L.A. Confidential (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "      <td>Heavyweights (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "      <td>Legends of the Fall (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "      <td>Jackie Brown (1997)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp                       title\n",
       "0      196      242       3  881250949                Kolya (1996)\n",
       "1      186      302       3  891717742    L.A. Confidential (1997)\n",
       "2       22      377       1  878887116         Heavyweights (1994)\n",
       "3      244       51       2  880606923  Legends of the Fall (1994)\n",
       "4      166      346       1  886397596         Jackie Brown (1997)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "\n",
    "# --- Download the dataset if it doesn't exist ---\n",
    "if not os.path.exists('ml-100k'):\n",
    "    print(\"Downloading MovieLens 100k dataset...\")\n",
    "    url = 'http://files.grouplens.org/datasets/movielens/ml-100k.zip'\n",
    "    urlretrieve(url, 'ml-100k.zip')\n",
    "    with zipfile.ZipFile('ml-100k.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "    print(\"Download and extraction complete.\")\n",
    "\n",
    "# --- Load the data ---\n",
    "# u.data contains the ratings\n",
    "data_cols = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "ratings_df = pd.read_csv('ml-100k/u.data', sep='\\t', names=data_cols)\n",
    "\n",
    "# u.item contains movie titles\n",
    "item_cols = ['item_id', 'title'] + [f'col{i}' for i in range(22)] # Remaining columns are not needed\n",
    "movies_df = pd.read_csv('ml-100k/u.item', sep='|', names=item_cols, encoding='latin-1', usecols=['item_id', 'title'])\n",
    "\n",
    "# Merge the two dataframes to have movie titles and ratings in one place\n",
    "df = pd.merge(ratings_df, movies_df, on='item_id')\n",
    "\n",
    "print(\"Data loaded successfully!\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Data Preparation\n",
    "\n",
    "The raw data is a list of ratings. For matrix factorization, it's conceptually easier to think of our data as a large **user-item interaction matrix**, let's call it $R$. In this matrix:\n",
    "* The rows represent users.\n",
    "* The columns represent movies (items).\n",
    "* The value at cell $(u, i)$, denoted $R_{ui}$, is the rating user $u$ gave to movie $i$.\n",
    "\n",
    "This matrix is typically very **sparse**, as most users have only rated a small fraction of the available movies.\n",
    "\n",
    "Let's create this matrix using a Pandas pivot table. This will also help us determine the number of unique users and movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>1673</th>\n",
       "      <th>1674</th>\n",
       "      <th>1675</th>\n",
       "      <th>1676</th>\n",
       "      <th>1677</th>\n",
       "      <th>1678</th>\n",
       "      <th>1679</th>\n",
       "      <th>1680</th>\n",
       "      <th>1681</th>\n",
       "      <th>1682</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1682 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item_id  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
       "user_id                                                              ...   \n",
       "1         5.0   3.0   4.0   3.0   3.0   5.0   4.0   1.0   5.0   3.0  ...   \n",
       "2         4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   2.0  ...   \n",
       "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "5         4.0   3.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "\n",
       "item_id  1673  1674  1675  1676  1677  1678  1679  1680  1681  1682  \n",
       "user_id                                                              \n",
       "1         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "5         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[5 rows x 1682 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_user_item_matrix(df):\n",
    "    \"\"\"\n",
    "    Creates the user-item interaction matrix from the dataframe.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe containing user_id, item_id, and rating.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A user-item matrix with users as rows, items as columns, and ratings as values.\n",
    "                       NaNs indicate that a user has not rated an item.\n",
    "    \"\"\"\n",
    "    # TODO: Create a pivot table.\n",
    "    # The index should be 'user_id', columns 'item_id', and values 'rating'.\n",
    "    \n",
    "    return df.pivot(index=\"user_id\", columns=\"item_id\", values=\"rating\")\n",
    "    \n",
    "pivot_df = create_user_item_matrix(df)\n",
    "\n",
    "pivot_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: The Theory of Matrix Factorization\n",
    "\n",
    "The core idea is to **decompose** our large, sparse user-item matrix $R$ (size $m \\times n$) into two smaller, dense matrices:\n",
    "1.  A **user-feature matrix** $P$ (size $m \\times k$).\n",
    "2.  An **item-feature matrix** $Q$ (size $n \\times k$).\n",
    "\n",
    "Here, $k$ is the number of **latent factors**, which is a hyperparameter we choose. These latent factors represent hidden characteristics of users and items. For movies, a factor might represent the \"amount of comedy\" vs. \"drama\", or \"blockbuster\" vs. \"indie film\". For users, a factor might represent their preference for these characteristics.\n",
    "\n",
    "\n",
    "\n",
    "The prediction of a rating $\\hat{r}_{ui}$ that user $u$ would give to item $i$ is calculated by the dot product of the user's latent vector $p_u$ and the item's latent vector $q_i$:\n",
    "\n",
    "$$\\hat{r}_{ui} = p_u \\cdot q_i^T = \\sum_{k=1}^{K} p_{uk} q_{ik}$$\n",
    "\n",
    "Our goal is to find the matrices $P$ and $Q$ such that their product $P \\cdot Q^T$ is as close as possible to the known ratings in our original matrix $R$. We formalize this using a **loss function**. A common choice is the sum of squared errors, with **regularization** to prevent overfitting:\n",
    "\n",
    "$$L = \\sum_{(u,i) \\in \\mathcal{K}} (r_{ui} - \\hat{r}_{ui})^2 + \\lambda \\left( \\sum_{u} ||p_u||^2 + \\sum_{i} ||q_i||^2 \\right)$$\n",
    "\n",
    "Where:\n",
    "* $\\mathcal{K}$ is the set of $(u, i)$ pairs for which the rating $r_{ui}$ is known.\n",
    "* $\\lambda$ is the regularization parameter, another hyperparameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: The Algorithm - Stochastic Gradient Descent (SGD)\n",
    "\n",
    "To minimize our loss function $L$, we will use **Stochastic Gradient Descent (SGD)**. Instead of calculating the gradient over all known ratings (which is computationally expensive), SGD iterates through each known rating one by one and updates the parameters in the direction that minimizes the error for that single rating.\n",
    "\n",
    "For each known rating $r_{ui}$:\n",
    "1.  Calculate the prediction error: $e_{ui} = r_{ui} - \\hat{r}_{ui}$\n",
    "2.  Update the user and item latent vectors ($p_u$ and $q_i$) using the following update rules:\n",
    "\n",
    "$$p_u \\leftarrow p_u + \\alpha \\cdot (e_{ui} \\cdot q_i - \\lambda \\cdot p_u)$$\n",
    "$$q_i \\leftarrow q_i + \\alpha \\cdot (e_{ui} \\cdot p_u - \\lambda \\cdot q_i)$$\n",
    "\n",
    "Where:\n",
    "* $\\alpha$ is the **learning rate**, a hyperparameter that controls the step size.\n",
    "\n",
    "We repeat this process for a fixed number of **epochs** (iterations over the entire training dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Step-by-Step Implementation\n",
    "\n",
    "Let's build our model. First, we need to split our data into a training and a testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Initialization\n",
    "\n",
    "We need to initialize our user-feature matrix $P$ and item-feature matrix $Q$ with small random values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_matrices(n_users, n_items, n_factors):\n",
    "    \"\"\"\n",
    "    Initializes the user-feature (P) and item-feature (Q) matrices.\n",
    "\n",
    "    Args:\n",
    "        n_users (int): Number of users.\n",
    "        n_items (int): Number of items.\n",
    "        n_factors (int): Number of latent factors.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - P (np.ndarray): The user-feature matrix (n_users x n_factors).\n",
    "            - Q (np.ndarray): The item-feature matrix (n_items x n_factors).\n",
    "    \"\"\"\n",
    "    # TODO: Initialize P and Q with small random values from a standard normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 The Training Loop (SGD)\n",
    "\n",
    "This is the core of our algorithm. We will loop for a specified number of epochs. In each epoch, we will iterate over all known ratings in our training set `R_train` and update the corresponding user and item vectors in `P` and `Q`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(R_train, P, Q, learning_rate, regularization, epochs):\n",
    "    \"\"\"\n",
    "    Trains the matrix factorization model using SGD.\n",
    "\n",
    "    Args:\n",
    "        R_train (np.ndarray): The training user-item matrix.\n",
    "        P (np.ndarray): The user-feature matrix.\n",
    "        Q (np.ndarray): The item-feature matrix.\n",
    "        learning_rate (float): The learning rate (alpha).\n",
    "        regularization (float): The regularization parameter (lambda).\n",
    "        epochs (int): The number of iterations over the training data.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the trained P and Q matrices.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Evaluation\n",
    "\n",
    "After training, we must evaluate how well our model performs on unseen data. We will use the **Root Mean Squared Error (RMSE)**, which measures the average magnitude of the errors between predicted and actual ratings.\n",
    "\n",
    "The formula is:\n",
    "$$RMSE = \\sqrt{\\frac{1}{|\\mathcal{T}|} \\sum_{(u,i) \\in \\mathcal{T}} (r_{ui} - \\hat{r}_{ui})^2}$$\n",
    "\n",
    "Where $\\mathcal{T}$ is the set of ratings in our test set. A lower RMSE means better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(R_test, P, Q):\n",
    "    \"\"\"\n",
    "    Calculates the Root Mean Squared Error (RMSE) on the test set.\n",
    "\n",
    "    Args:\n",
    "        R_test (np.ndarray): The testing user-item matrix.\n",
    "        P (np.ndarray): The trained user-feature matrix.\n",
    "        Q (np.ndarray): The trained item-feature matrix.\n",
    "\n",
    "    Returns:\n",
    "        float: The RMSE value.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6: Putting It All Together\n",
    "\n",
    "Now, let's connect all the pieces. We'll set our hyperparameters, initialize our matrices, train the model, and finally evaluate it.\n",
    "\n",
    "**Your Goal:** Tune the hyperparameters to achieve an **RMSE below 0.98**. A good model can even reach ~0.95. If your RMSE is higher, try adjusting the learning rate, regularization, number of factors, or epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hyperparameters ---\n",
    "# Number of latent factors (k)\n",
    "# Learning rate (alpha)\n",
    "# Regularization parameter (lambda)\n",
    "# Number of epochs\n",
    "\n",
    "# --- Initialization ---\n",
    "# Remember user and item IDs are 1-based, but our numpy arrays are 0-based.\n",
    "# The number of users/items from the shape of R_df is correct for 0-based indexing.\n",
    "\n",
    "# --- Training ---\n",
    "\n",
    "\n",
    "# --- Evaluation ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Making Recommendations\n",
    "\n",
    "The ultimate goal is to recommend movies! Now that we have our trained matrices $P$ and $Q$, we can predict the rating for *any* user-item pair, including those the user has not seen yet.\n",
    "\n",
    "The process for a given user `user_id`:\n",
    "1.  Get the user's latent vector $p_u$ from the trained matrix $P$.\n",
    "2.  Calculate the predicted ratings for all items by taking the dot product of $p_u$ and the entire item-feature matrix $Q^T$.\n",
    "3.  Create a list of movie titles and their predicted ratings.\n",
    "4.  Filter out movies the user has already seen.\n",
    "5.  Sort the remaining movies by their predicted rating in descending order.\n",
    "6.  Return the top N movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_top_movies(user_id, P, Q, movie_titles_df, R_df, top_n=10):\n",
    "    \"\"\"\n",
    "    Recommends top N movies for a given user.\n",
    "\n",
    "    Args:\n",
    "        user_id (int): The ID of the user.\n",
    "        P (np.ndarray): The trained user-feature matrix.\n",
    "        Q (np.ndarray): The trained item-feature matrix.\n",
    "        movie_titles_df (pd.DataFrame): Dataframe with item_id and title.\n",
    "        R_df (pd.DataFrame): The original user-item matrix dataframe (for checking seen movies).\n",
    "        top_n (int): The number of movies to recommend.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A dataframe with the top N recommended movie titles and their predicted ratings.\n",
    "    \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
